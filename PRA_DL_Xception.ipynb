{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PRA DL Xception.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaRQOqW6s6OqUy2COZflKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etodasha/PRA-M2.875-2020.2/blob/main/PRA_DL_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "8nxDDu1HzldK",
        "outputId": "7c8fb09f-d22d-4a5d-d77c-03c2c6969ef5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-93fd1bb1-293f-4df5-b1df-7f4d69175aaa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-93fd1bb1-293f-4df5-b1df-7f4d69175aaa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 69 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ7BnGIX2N_N",
        "outputId": "e0688bc6-08e8-45b0-ada5-b2e47ffb7c31"
      },
      "source": [
        "!kaggle datasets download \"jordidelatorreuoc/kaggle-plant-pathology-2021-modificat\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading kaggle-plant-pathology-2021-modificat.zip to /content\n",
            " 98% 955M/970M [00:05<00:00, 129MB/s]\n",
            "100% 970M/970M [00:05<00:00, 170MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbFKkDt2fZm"
      },
      "source": [
        "!unzip kaggle-plant-pathology-2021-modificat.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DFjFKRb2fhv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import keras \n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout, ZeroPadding2D, GlobalAveragePooling2D,BatchNormalization\n",
        "from keras.optimizers import Adam, SGD,RMSprop,Adadelta,Adagrad,Adamax,Nadam,Ftrl\n",
        "from keras.layers.experimental.preprocessing import Resizing\n",
        "from keras.callbacks import *\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,Add\n",
        "from tensorflow.keras.layers import SeparableConv2D,ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization,MaxPool2D\n",
        "from tensorflow.keras.layers import GlobalAvgPool2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_74pvMwbCERU"
      },
      "source": [
        "DATA AUGMENTATION + TRAIN VALIDATION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMvmnrJsCCqP",
        "outputId": "3ebd9411-d03d-4128-941e-c178b6097e9e"
      },
      "source": [
        "datagen_train = ImageDataGenerator(\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    zoom_range=[0.5,1.2],\n",
        "    rotation_range=20,\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2) \n",
        "\n",
        "train_generator = datagen_train.flow_from_directory( \n",
        "    'train',\n",
        "    subset='training')\n",
        "\n",
        "validation_generator = datagen_train.flow_from_directory(\n",
        "    'train',\n",
        "    subset='validation'\n",
        "    ,shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7800 images belonging to 6 classes.\n",
            "Found 1950 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_YjCvftCd13"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def custom_recall(y_true, y_pred):\n",
        "  TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  recall = TP / (Positives+K.epsilon())\n",
        "  return recall \n",
        "\n",
        "def custom_precision(y_true, y_pred):\n",
        "  TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = TP / (Pred_Positives+K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def custom_f1(y_true, y_pred):    \n",
        "    precision, recall = custom_precision(y_true, y_pred), custom_recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77aEoBwWYnRg",
        "outputId": "6a05a329-ee58-4a20-9813-00bc1e7885f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrdNThkHiEKc",
        "outputId": "c77715d2-25a0-4d82-8726-949def25e66c"
      },
      "source": [
        "def conv_bn(x, filters, kernel_size, strides=1):\n",
        "    \n",
        "    x = Conv2D(filters=filters, \n",
        "               kernel_size = kernel_size, \n",
        "               strides=strides, \n",
        "               padding = 'same', \n",
        "               use_bias = False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def sep_bn(x, filters, kernel_size, strides=1):\n",
        "    \n",
        "    x = SeparableConv2D(filters=filters, \n",
        "                        kernel_size = kernel_size, \n",
        "                        strides=strides, \n",
        "                        padding = 'same', \n",
        "                        use_bias = False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "def entry_flow(x):\n",
        "    \n",
        "    x = Resizing(299,299)(x)\n",
        "\n",
        "    x = conv_bn(x, filters =32, kernel_size =3, strides=2)\n",
        "    x = ReLU()(x)\n",
        "    x = conv_bn(x, filters =64, kernel_size =3, strides=1)\n",
        "    tensor = ReLU()(x)\n",
        "    \n",
        "    x = sep_bn(tensor, filters = 128, kernel_size =3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 128, kernel_size =3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=128, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =256, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=256, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters =728, kernel_size=3)\n",
        "    x = MaxPool2D(pool_size=3, strides=2, padding = 'same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters=728, kernel_size = 1,strides=2)\n",
        "    x = Add()([tensor,x])\n",
        "    return x\n",
        "\n",
        "def middle_flow(tensor):\n",
        "    \n",
        "    for _ in range(8):\n",
        "        x = ReLU()(tensor)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        x = sep_bn(x, filters = 728, kernel_size = 3)\n",
        "        x = ReLU()(x)\n",
        "        tensor = Add()([tensor,x])\n",
        "        return tensor\n",
        "\n",
        "def exit_flow(tensor):\n",
        "    \n",
        "    x = ReLU()(tensor)\n",
        "    x = sep_bn(x, filters = 728,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 1024,  kernel_size=3)\n",
        "    x = MaxPool2D(pool_size = 3, strides = 2, padding ='same')(x)\n",
        "    \n",
        "    tensor = conv_bn(tensor, filters =1024, kernel_size=1, strides =2)\n",
        "    x = Add()([tensor,x])\n",
        "    \n",
        "    x = sep_bn(x, filters = 1536,  kernel_size=3)\n",
        "    x = ReLU()(x)\n",
        "    x = sep_bn(x, filters = 2048,  kernel_size=3)\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    \n",
        "    x = Dense (units = 1000, activation = 'relu')(x)\n",
        "\n",
        "    x = Dense (units = 6, activation = 'softmax')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "input = Input(shape = (332, 498,3))\n",
        "x = entry_flow(input)\n",
        "x = middle_flow(x)\n",
        "output = exit_flow(x)\n",
        "\n",
        "model = Model (inputs=input, outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 332, 498, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "resizing (Resizing)             (None, 299, 299, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 150, 150, 32) 864         resizing[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 150, 150, 32) 128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 150, 150, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 150, 150, 64) 18432       re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 150, 150, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 150, 150, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 150, 150, 128 8768        re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 150, 150, 128 512         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 150, 150, 128 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 150, 150, 128 17536       re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 75, 75, 128)  8192        re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 150, 150, 128 512         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 75, 75, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 75, 75, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 75, 75, 128)  0           batch_normalization_4[0][0]      \n",
            "                                                                 max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 75, 75, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 75, 75, 256)  33920       re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 75, 75, 256)  1024        separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 75, 75, 256)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 75, 75, 256)  67840       re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 38, 38, 256)  32768       batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 75, 75, 256)  1024        separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 38, 38, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 38, 38, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 38, 38, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 38, 38, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 38, 38, 728)  188672      re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 38, 38, 728)  2912        separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 38, 38, 728)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 38, 38, 728)  536536      re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 19, 19, 728)  186368      batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 38, 38, 728)  2912        separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 19, 19, 728)  2912        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 19, 19, 728)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 19, 19, 728)  0           batch_normalization_10[0][0]     \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 19, 19, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 19, 19, 728)  536536      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 19, 19, 728)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 19, 19, 728)  536536      re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 19, 19, 728)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 19, 19, 728)  536536      re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 19, 19, 728)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           add_2[0][0]                      \n",
            "                                                                 re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 19, 19, 728)  536536      re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 19, 19, 728)  2912        separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 19, 19, 728)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 19, 19, 1024) 752024      re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 10, 10, 1024) 745472      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 19, 19, 1024) 4096        separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 10, 10, 1024) 4096        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 10, 10, 1024) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 10, 10, 1024) 0           batch_normalization_16[0][0]     \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 10, 10, 1536) 1582080     add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 10, 10, 1536) 6144        separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 10, 10, 1536) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 10, 10, 2048) 3159552     re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 10, 10, 2048) 8192        separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1000)         2049000     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            6006        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 11,588,078\n",
            "Trainable params: 11,564,126\n",
            "Non-trainable params: 23,952\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q4jftASiSvf",
        "outputId": "695a24cb-bfa4-4f63-cc7f-96a3ec9b82af"
      },
      "source": [
        "# Xception\n",
        "model.compile(optimizer = Adam(learning_rate=0.0001), \n",
        "              loss = \"categorical_crossentropy\", \n",
        "              metrics = ['accuracy',custom_f1,custom_recall,custom_precision])\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_custom_f1', mode='max', patience=15, \n",
        "                                               restore_best_weights=True, verbose=2)\n",
        "\n",
        "filepath = \"/content/gdrive/My Drive/Xception_epochs:{epoch:03d}-val_f1:{val_custom_f1:.3f}.hdf5\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(filepath= filepath, monitor='val_custom_f1', mode='max',\n",
        "                                                         save_weights_only=True, save_best_only=True)\n",
        "\n",
        "\n",
        "model_history = model.fit(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              epochs=100,\n",
        "                              batch_size=512,\n",
        "                              callbacks=[early_stopping, checkpoint_callback]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "244/244 [==============================] - 268s 947ms/step - loss: 1.2461 - accuracy: 0.5463 - custom_f1: 0.4634 - custom_recall: 0.3599 - custom_precision: 0.6817 - val_loss: 1.7091 - val_accuracy: 0.4103 - val_custom_f1: 0.0000e+00 - val_custom_recall: 0.0000e+00 - val_custom_precision: 0.0000e+00\n",
            "Epoch 2/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.9122 - accuracy: 0.6704 - custom_f1: 0.6512 - custom_recall: 0.5725 - custom_precision: 0.7607 - val_loss: 2.0588 - val_accuracy: 0.4103 - val_custom_f1: 0.4067 - val_custom_recall: 0.4037 - val_custom_precision: 0.4098\n",
            "Epoch 3/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.7817 - accuracy: 0.7190 - custom_f1: 0.7068 - custom_recall: 0.6457 - custom_precision: 0.7843 - val_loss: 1.4265 - val_accuracy: 0.5267 - val_custom_f1: 0.4906 - val_custom_recall: 0.4641 - val_custom_precision: 0.5344\n",
            "Epoch 4/100\n",
            "244/244 [==============================] - 229s 939ms/step - loss: 0.6943 - accuracy: 0.7531 - custom_f1: 0.7464 - custom_recall: 0.6934 - custom_precision: 0.8101 - val_loss: 0.6942 - val_accuracy: 0.7508 - val_custom_f1: 0.7386 - val_custom_recall: 0.6921 - val_custom_precision: 0.7935\n",
            "Epoch 5/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.6255 - accuracy: 0.7792 - custom_f1: 0.7750 - custom_recall: 0.7331 - custom_precision: 0.8241 - val_loss: 0.7201 - val_accuracy: 0.7400 - val_custom_f1: 0.7138 - val_custom_recall: 0.6867 - val_custom_precision: 0.7497\n",
            "Epoch 6/100\n",
            "244/244 [==============================] - 230s 939ms/step - loss: 0.5415 - accuracy: 0.8133 - custom_f1: 0.8131 - custom_recall: 0.7785 - custom_precision: 0.8523 - val_loss: 0.7327 - val_accuracy: 0.7687 - val_custom_f1: 0.7618 - val_custom_recall: 0.7407 - val_custom_precision: 0.7852\n",
            "Epoch 7/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.5072 - accuracy: 0.8260 - custom_f1: 0.8243 - custom_recall: 0.7931 - custom_precision: 0.8593 - val_loss: 0.5829 - val_accuracy: 0.8026 - val_custom_f1: 0.7940 - val_custom_recall: 0.7657 - val_custom_precision: 0.8266\n",
            "Epoch 8/100\n",
            "244/244 [==============================] - 230s 943ms/step - loss: 0.4699 - accuracy: 0.8378 - custom_f1: 0.8368 - custom_recall: 0.8084 - custom_precision: 0.8683 - val_loss: 0.5850 - val_accuracy: 0.8021 - val_custom_f1: 0.7992 - val_custom_recall: 0.7752 - val_custom_precision: 0.8268\n",
            "Epoch 9/100\n",
            "244/244 [==============================] - 231s 945ms/step - loss: 0.4484 - accuracy: 0.8492 - custom_f1: 0.8498 - custom_recall: 0.8237 - custom_precision: 0.8788 - val_loss: 0.5576 - val_accuracy: 0.8072 - val_custom_f1: 0.8035 - val_custom_recall: 0.7709 - val_custom_precision: 0.8407\n",
            "Epoch 10/100\n",
            "244/244 [==============================] - 229s 939ms/step - loss: 0.4196 - accuracy: 0.8590 - custom_f1: 0.8566 - custom_recall: 0.8313 - custom_precision: 0.8846 - val_loss: 0.7136 - val_accuracy: 0.7487 - val_custom_f1: 0.7466 - val_custom_recall: 0.7138 - val_custom_precision: 0.7855\n",
            "Epoch 11/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.4191 - accuracy: 0.8578 - custom_f1: 0.8573 - custom_recall: 0.8363 - custom_precision: 0.8801 - val_loss: 0.6202 - val_accuracy: 0.8128 - val_custom_f1: 0.8125 - val_custom_recall: 0.7984 - val_custom_precision: 0.8285\n",
            "Epoch 12/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.3972 - accuracy: 0.8654 - custom_f1: 0.8627 - custom_recall: 0.8410 - custom_precision: 0.8863 - val_loss: 0.4715 - val_accuracy: 0.8338 - val_custom_f1: 0.8323 - val_custom_recall: 0.8133 - val_custom_precision: 0.8535\n",
            "Epoch 13/100\n",
            "244/244 [==============================] - 230s 943ms/step - loss: 0.3840 - accuracy: 0.8721 - custom_f1: 0.8696 - custom_recall: 0.8478 - custom_precision: 0.8933 - val_loss: 0.4833 - val_accuracy: 0.8436 - val_custom_f1: 0.8366 - val_custom_recall: 0.8212 - val_custom_precision: 0.8543\n",
            "Epoch 14/100\n",
            "244/244 [==============================] - 230s 941ms/step - loss: 0.3917 - accuracy: 0.8676 - custom_f1: 0.8673 - custom_recall: 0.8466 - custom_precision: 0.8897 - val_loss: 0.4719 - val_accuracy: 0.8395 - val_custom_f1: 0.8369 - val_custom_recall: 0.8130 - val_custom_precision: 0.8639\n",
            "Epoch 15/100\n",
            "244/244 [==============================] - 229s 938ms/step - loss: 0.3639 - accuracy: 0.8763 - custom_f1: 0.8756 - custom_recall: 0.8570 - custom_precision: 0.8958 - val_loss: 0.5403 - val_accuracy: 0.8200 - val_custom_f1: 0.8162 - val_custom_recall: 0.7986 - val_custom_precision: 0.8363\n",
            "Epoch 16/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.3560 - accuracy: 0.8817 - custom_f1: 0.8822 - custom_recall: 0.8654 - custom_precision: 0.9004 - val_loss: 0.5165 - val_accuracy: 0.8385 - val_custom_f1: 0.8346 - val_custom_recall: 0.8210 - val_custom_precision: 0.8499\n",
            "Epoch 17/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.3454 - accuracy: 0.8823 - custom_f1: 0.8824 - custom_recall: 0.8653 - custom_precision: 0.9007 - val_loss: 0.4457 - val_accuracy: 0.8595 - val_custom_f1: 0.8560 - val_custom_recall: 0.8426 - val_custom_precision: 0.8707\n",
            "Epoch 18/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.3305 - accuracy: 0.8851 - custom_f1: 0.8855 - custom_recall: 0.8690 - custom_precision: 0.9032 - val_loss: 0.4557 - val_accuracy: 0.8564 - val_custom_f1: 0.8533 - val_custom_recall: 0.8412 - val_custom_precision: 0.8663\n",
            "Epoch 19/100\n",
            "244/244 [==============================] - 231s 944ms/step - loss: 0.3333 - accuracy: 0.8887 - custom_f1: 0.8884 - custom_recall: 0.8716 - custom_precision: 0.9065 - val_loss: 0.4256 - val_accuracy: 0.8641 - val_custom_f1: 0.8632 - val_custom_recall: 0.8492 - val_custom_precision: 0.8790\n",
            "Epoch 20/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.3082 - accuracy: 0.8949 - custom_f1: 0.8954 - custom_recall: 0.8811 - custom_precision: 0.9107 - val_loss: 0.4323 - val_accuracy: 0.8646 - val_custom_f1: 0.8590 - val_custom_recall: 0.8481 - val_custom_precision: 0.8707\n",
            "Epoch 21/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.3238 - accuracy: 0.8881 - custom_f1: 0.8890 - custom_recall: 0.8742 - custom_precision: 0.9048 - val_loss: 0.4703 - val_accuracy: 0.8467 - val_custom_f1: 0.8443 - val_custom_recall: 0.8272 - val_custom_precision: 0.8632\n",
            "Epoch 22/100\n",
            "244/244 [==============================] - 230s 942ms/step - loss: 0.3173 - accuracy: 0.8912 - custom_f1: 0.8910 - custom_recall: 0.8772 - custom_precision: 0.9056 - val_loss: 0.3455 - val_accuracy: 0.8800 - val_custom_f1: 0.8811 - val_custom_recall: 0.8705 - val_custom_precision: 0.8924\n",
            "Epoch 23/100\n",
            "244/244 [==============================] - 230s 941ms/step - loss: 0.3070 - accuracy: 0.8929 - custom_f1: 0.8938 - custom_recall: 0.8795 - custom_precision: 0.9089 - val_loss: 0.4194 - val_accuracy: 0.8636 - val_custom_f1: 0.8624 - val_custom_recall: 0.8462 - val_custom_precision: 0.8803\n",
            "Epoch 24/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.2996 - accuracy: 0.8985 - custom_f1: 0.8976 - custom_recall: 0.8838 - custom_precision: 0.9122 - val_loss: 0.3782 - val_accuracy: 0.8672 - val_custom_f1: 0.8681 - val_custom_recall: 0.8582 - val_custom_precision: 0.8789\n",
            "Epoch 25/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.2967 - accuracy: 0.8983 - custom_f1: 0.8979 - custom_recall: 0.8834 - custom_precision: 0.9133 - val_loss: 0.6845 - val_accuracy: 0.7918 - val_custom_f1: 0.7878 - val_custom_recall: 0.7750 - val_custom_precision: 0.8021\n",
            "Epoch 26/100\n",
            "244/244 [==============================] - 229s 938ms/step - loss: 0.2735 - accuracy: 0.9099 - custom_f1: 0.9087 - custom_recall: 0.8968 - custom_precision: 0.9213 - val_loss: 0.5334 - val_accuracy: 0.8221 - val_custom_f1: 0.8221 - val_custom_recall: 0.8037 - val_custom_precision: 0.8424\n",
            "Epoch 27/100\n",
            "244/244 [==============================] - 229s 939ms/step - loss: 0.2788 - accuracy: 0.9044 - custom_f1: 0.9043 - custom_recall: 0.8935 - custom_precision: 0.9158 - val_loss: 0.6000 - val_accuracy: 0.7856 - val_custom_f1: 0.7820 - val_custom_recall: 0.7691 - val_custom_precision: 0.7961\n",
            "Epoch 28/100\n",
            "244/244 [==============================] - 230s 943ms/step - loss: 0.2818 - accuracy: 0.9028 - custom_f1: 0.9006 - custom_recall: 0.8890 - custom_precision: 0.9131 - val_loss: 0.3389 - val_accuracy: 0.8821 - val_custom_f1: 0.8789 - val_custom_recall: 0.8672 - val_custom_precision: 0.8916\n",
            "Epoch 29/100\n",
            "244/244 [==============================] - 230s 941ms/step - loss: 0.2686 - accuracy: 0.9104 - custom_f1: 0.9099 - custom_recall: 0.8986 - custom_precision: 0.9218 - val_loss: 0.5006 - val_accuracy: 0.8533 - val_custom_f1: 0.8523 - val_custom_recall: 0.8427 - val_custom_precision: 0.8627\n",
            "Epoch 30/100\n",
            "244/244 [==============================] - 230s 941ms/step - loss: 0.2577 - accuracy: 0.9114 - custom_f1: 0.9106 - custom_recall: 0.8994 - custom_precision: 0.9223 - val_loss: 0.4650 - val_accuracy: 0.8436 - val_custom_f1: 0.8422 - val_custom_recall: 0.8137 - val_custom_precision: 0.8745\n",
            "Epoch 31/100\n",
            "244/244 [==============================] - 230s 939ms/step - loss: 0.2546 - accuracy: 0.9119 - custom_f1: 0.9108 - custom_recall: 0.9002 - custom_precision: 0.9220 - val_loss: 0.4793 - val_accuracy: 0.8503 - val_custom_f1: 0.8462 - val_custom_recall: 0.8365 - val_custom_precision: 0.8568\n",
            "Epoch 32/100\n",
            "244/244 [==============================] - 230s 939ms/step - loss: 0.2574 - accuracy: 0.9129 - custom_f1: 0.9132 - custom_recall: 0.9033 - custom_precision: 0.9238 - val_loss: 0.5955 - val_accuracy: 0.8221 - val_custom_f1: 0.8206 - val_custom_recall: 0.8107 - val_custom_precision: 0.8315\n",
            "Epoch 33/100\n",
            "244/244 [==============================] - 230s 939ms/step - loss: 0.2450 - accuracy: 0.9162 - custom_f1: 0.9161 - custom_recall: 0.9049 - custom_precision: 0.9279 - val_loss: 0.5592 - val_accuracy: 0.8374 - val_custom_f1: 0.8359 - val_custom_recall: 0.8232 - val_custom_precision: 0.8499\n",
            "Epoch 34/100\n",
            "244/244 [==============================] - 230s 940ms/step - loss: 0.2493 - accuracy: 0.9156 - custom_f1: 0.9158 - custom_recall: 0.9061 - custom_precision: 0.9259 - val_loss: 0.5025 - val_accuracy: 0.8497 - val_custom_f1: 0.8501 - val_custom_recall: 0.8417 - val_custom_precision: 0.8590\n",
            "Epoch 35/100\n",
            "244/244 [==============================] - 230s 939ms/step - loss: 0.2418 - accuracy: 0.9182 - custom_f1: 0.9191 - custom_recall: 0.9095 - custom_precision: 0.9293 - val_loss: 0.4102 - val_accuracy: 0.8651 - val_custom_f1: 0.8647 - val_custom_recall: 0.8445 - val_custom_precision: 0.8870\n",
            "Epoch 36/100\n",
            "244/244 [==============================] - 230s 943ms/step - loss: 0.2395 - accuracy: 0.9187 - custom_f1: 0.9177 - custom_recall: 0.9090 - custom_precision: 0.9269 - val_loss: 0.5111 - val_accuracy: 0.8477 - val_custom_f1: 0.8449 - val_custom_recall: 0.8379 - val_custom_precision: 0.8524\n",
            "Epoch 37/100\n",
            "244/244 [==============================] - 229s 937ms/step - loss: 0.2284 - accuracy: 0.9221 - custom_f1: 0.9224 - custom_recall: 0.9147 - custom_precision: 0.9306 - val_loss: 0.7373 - val_accuracy: 0.7831 - val_custom_f1: 0.7829 - val_custom_recall: 0.7734 - val_custom_precision: 0.7932\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00037: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2OLwFfrG2Qf"
      },
      "source": [
        "#xception 0.8811 ('/content/gdrive/My Drive/Xcpetion_epochs:22-val_f1:0.881.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}